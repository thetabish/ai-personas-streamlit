# Synthetisches Interview System ğŸ¤

Automatisierte synthetische Interviews mit AI-Personas fÃ¼r Lifestyle-Marken-Forschung mit LangChain und OpenRouter.

**ğŸ“¦ Repository:** [github.com/thetabish/ai-personas](https://github.com/thetabish/ai-personas)

## Vor dem Start: API-SchlÃ¼ssel besorgen

**5-Sekunden Setup:**
1. Gehen Sie zu: https://openrouter.ai/mistralai/mistral-small-24b-instruct-2501:free/api
2. Erstellen Sie einen kostenlosen Account
3. Kopieren Sie Ihren API-SchlÃ¼ssel (beginnt mit `sk-or-v1-...`)
4. **SchlÃ¼ssel wird automatisch abgefragt!** â¬‡ï¸

## ğŸš€ Schnell-Start (5 Minuten)

### Linux/macOS:
```bash
# SSH (empfohlen)
git clone git@github.com:thetabish/ai-personas.git
# oder HTTPS
git clone https://github.com/thetabish/ai-personas.git

cd ai-personas
chmod +x run.sh && ./run.sh
# Script fragt automatisch nach API-SchlÃ¼ssel falls keiner vorhanden
```

### Windows:
```cmd
REM Command Prompt (cmd) - Empfohlen
git clone https://github.com/thetabish/ai-personas.git
cd ai-personas
run.bat
```

```powershell
# PowerShell - Alternative
git clone https://github.com/thetabish/ai-personas.git
cd ai-personas
.\run.bat
# oder: cmd /c run.bat
```

> **Was machen die Scripts?** `run.sh` und `run.bat` sind vollautomatische Setup-Scripts, die:
> - Python-Installation prÃ¼fen
> - Virtuelle Umgebung erstellen  
> - Alle AbhÃ¤ngigkeiten installieren
> - API-SchlÃ¼ssel interaktiv abfragen (falls fehlend)
> - Sofort eine Demo mit 3 AI-Personas starten

**Das war's!** Die Scripts richten automatisch alles ein:
âœ… Python prÃ¼fen âœ… AbhÃ¤ngigkeiten installieren âœ… **API interaktiv eingeben** âœ… Demo starten

**ğŸ’¡ Windows-Tipp:** Bei PowerShell verwenden Sie `.\run.bat` - Command Prompt (cmd) ist empfohlen!

**Demo-Ergebnis:** 3 AI-Personas (Anna, Tom, Julia) beantworten Lifestyle-Fragen
- Ausgabe: `results.json` (Daten) und `results.md` (Bericht)

## âœ¨ Features

- ğŸ¤– **3 einzigartige AI-Personas** (Anna, Tom, Julia)
- ğŸ¯ **Flexibler Interview-Modus** (alle Personas oder einzeln)
- ï¿½ **Batch-Processing** (automatisierte Studien + Cron-UnterstÃ¼tzung)
- ï¿½ğŸ”— **LangChain + OpenRouter** (kostenlos)
- ğŸ“ **JSON-Fragensystem** (einfach anpassbar)
- ğŸ’» **CLI & Python API** (Kommandozeile + programmierbar)
- ğŸ“Š **JSON/Markdown Ausgabe** (strukturierte Daten + Berichte)
- ğŸ§  **UnabhÃ¤ngige Persona-GedÃ¤chtnisse** (konsistente Antworten)
- âš¡ **Kostenfrei** (Mistral AI Ã¼ber OpenRouter)

## ğŸ”§ Manuelle Installation

**Voraussetzungen:** Python 3.8+

```bash
# 1. Repository klonen
git clone git@github.com:thetabish/ai-personas.git
# oder: git clone https://github.com/thetabish/ai-personas.git
cd ai-personas

# 2. AbhÃ¤ngigkeiten installieren
pip install -r requirements.txt

# 3. API-SchlÃ¼ssel einrichten
cp .env.example .env
# Bearbeiten Sie .env und fÃ¼gen Sie Ihren OpenRouter API-SchlÃ¼ssel ein:
# OPENROUTER_API_KEY=sk-or-v1-ihr_schluessel_hier
# SchlÃ¼ssel erhalten: https://openrouter.ai/mistralai/mistral-small-24b-instruct-2501:free/api

# 4. Demo starten
python interview.py --questions questions.json
```

## ğŸ’» Verwendung

### CLI (Kommandozeile)
```bash
# Basis-Interview
 (alle Personas, Markdown-Ausgabe)
python interview.py --questions questions.json

# JSON-Format gewÃ¼nscht
python interview.py --questions questions.json --format json

# Eigene Ausgabedatei  
python interview.py --questions questions.json --output meine_befragung
```

### Programmable API (Python Import)

**Flexibler `run_interview()` - zwei Modi:**

#### 1. Alle Personas (Standard)
```python
from interview import run_interview

# Alle 3 Personas antworten (Anna, Tom, Julia)
results = run_interview("questions.json")

# Mit Format-Optionen
results = run_interview("questions.json", format="json")
results = run_interview("questions.json", output_file="my_study")
```

#### 2. Einzelne Persona
```python
# Nur Anna antwortet
results = run_interview("anna", "questions.json")

# Nur Tom antwortet
results = run_interview("tom", "questions.json") 

# Nur Julia antwortet
results = run_interview("julia", "questions.json")

# Mit Format-Optionen
results = run_interview("anna", "questions.json", format="json")
```

**VerfÃ¼gbare Agenten abrufen:**
```python
from interview import get_available_agents
agents = get_available_agents()  # ['anna', 'tom', 'julia']
```

### Batch-Interviews (Automatisierung) ğŸ”„

**FÃ¼r groÃŸe Studien, Forschungsautomatisierung und Cron-Jobs:**

#### Schnellstart
```bash
# Batch-Interview mit allen Agenten
python run_batch.py --config interview_batch.json

# Nur spezifische Agenten
python run_batch.py --config interview_batch.json --agents anna tom

# Stiller Modus fÃ¼r Cron-Jobs
python run_batch.py --config interview_batch.json --quiet
```

#### Kommandozeilen-Optionen

| Option | Beschreibung | Standard |
|--------|-------------|----------|
| `--config` | Pfad zur Batch-Konfiguration | `interview_batch.json` |
| `--output-dir` | Ergebnisordner | `batch_results` |
| `--log-file` | Log-Datei | `batch_interviews.log` |
| `--format` | Ausgabeformat (md/json) | `md` |
| `--agents` | Spezifische Agenten | `all` |
| `--quiet` | Stiller Modus fÃ¼r Automation | `false` |

#### Batch-Konfiguration (`interview_batch.json`)
```json
{
  "questions": [
    "Was ist dir bei einer Lifestyle-Marke am wichtigsten?",
    "Wie bewertest du Nachhaltigkeit bei den Marken, die du wÃ¤hlst?",
    "Welche Rolle spielt der Preis bei deinen Kaufentscheidungen?",
    "Bis zu 20+ weitere Fragen..."
  ],
  "metadata": {
    "description": "Lifestyle Marken Studie 2025",
    "version": "1.0",
    "research_focus": ["nachhaltigkeit", "markenwahrnehmung"]
  }
}
```

#### Cron-Job Setup (Automatisierung)
```bash
# TÃ¤gliche Interviews um 2:00 Uhr
0 2 * * * cd /path/to/ai-personas && python run_batch.py --config interview_batch.json --quiet

# WÃ¶chentliche umfassende Studie (Sonntags 3:00 Uhr)
0 3 * * 0 cd /path/to/ai-personas && python run_batch.py --config weekly_study.json --format json --quiet

# WerktÃ¤gliche Verbraucher-Sentiment-Studie
0 6 * * 1-5 cd /path/to/ai-personas && python run_batch.py --config daily_sentiment.json --quiet
```

#### Ausgabe-Struktur
```
batch_results/
â”œâ”€â”€ batch_all_agents_20250121_140530.md    # Alle Agenten
â”œâ”€â”€ batch_anna_20250121_140535.md          # Nur Anna
â”œâ”€â”€ batch_tom_20250121_140540.md           # Nur Tom
â””â”€â”€ batch_julia_20250121_140545.md         # Nur Julia

batch_interviews.log                        # Umfassendes Log
```

#### Log-Inhalt
Das Log umfasst:
- âœ… **Erfolg/Fehler-Status** fÃ¼r jedes Interview
- ï¿½ **Batch-Statistiken** (Erfolgsrate, Timing)
- ğŸš¨ **Fehlerdetails** fÃ¼r Fehlerbehebung  
- ğŸ• **Zeitstempel** fÃ¼r alle VorgÃ¤nge

#### Beispiele fÃ¼r Forschungsautomatisierung
```bash
# Morgendliche Verbraucherstimmung
python run_batch.py --config morning_sentiment.json --agents all --format md

# Individuelle Persona-Tiefenanalyse
python run_batch.py --config deep_dive.json --agents anna --format json

# A/B-Testing verschiedener Fragensets
python run_batch.py --config variant_a.json --output study_a
python run_batch.py --config variant_b.json --output study_b
```

#### Fehlerbehandlung & Robustheit
- **Einzelfehler** stoppen nicht das gesamte Batch
- **Umfassendes Logging** fÃ¼r Debugging
- **Exit-Codes** fÃ¼r Cron-Job-Monitoring
- **Automatische Bereinigung** temporÃ¤rer Dateien

**Perfekt fÃ¼r:**
- ğŸ“ˆ **Langzeitstudien** (tÃ¤gliche/wÃ¶chentliche Verfolgung)
- ï¿½ **A/B-Testing** verschiedener Fragensets
- ğŸ“Š **GroÃŸangelegte Forschung** mit mehreren Personas
- ğŸ¤– **Automatisierte Datensammlung** fÃ¼r Pipelines

### Eigene Fragen erstellen
```json
{
  "questions": [
    "Ihre erste Frage hier",
    "Ihre zweite Frage hier"
  ]
}
```

## ğŸ—ï¸ Technische Architektur & Entscheidungen

### Warum Mistral AI?
- **Kostenlos**: Mistral Small Ã¼ber OpenRouter ist vÃ¶llig kostenlos
- **QualitÃ¤t**: Hochwertiges mehrsprachiges Modell (DE/EN)
- **Performance**: Schnelle Antwortzeiten fÃ¼r Interviews
- **Konsistenz**: Stabile Persona-Charakteristiken

### Warum OpenRouter?
- **Kostenkontrolle**: Kostenlose Modelle ohne versteckte GebÃ¼hren
- **Einfachheit**: Ein API-SchlÃ¼ssel fÃ¼r viele AI-Modelle
- **ZuverlÃ¤ssigkeit**: Professioneller API-Gateway mit hoher VerfÃ¼gbarkeit
- **FlexibilitÃ¤t**: Einfacher Modellwechsel ohne Code-Ã„nderungen

### LangChain Integration
```python
# Vereinfachter Workflow:
PersonaAgent â†’ LangChain â†’ OpenRouter â†’ Mistral AI â†’ Antwort
```

**Warum LangChain?**
- **Abstraktion**: Einheitliche Schnittstelle fÃ¼r verschiedene AI-Modelle
- **Kontext-Management**: Automatische Verwaltung von GesprÃ¤chsverlÃ¤ufen
- **Prompt-Engineering**: Strukturierte Prompts fÃ¼r konsistente Ergebnisse
- **Zukunftssicherheit**: Einfacher Wechsel zwischen AI-Anbietern

### Programm-Flow
1. **Setup**: API-Validierung â†’ Persona-Erstellung (LangChain)
2. **Interview**: Jede Persona antwortet unabhÃ¤ngig (eigener Kontext)
3. **Speicherung**: Strukturierte JSON/Markdown-Ausgabe
4. **GedÃ¤chtnis**: Personas erinnern sich an eigene Antworten (konsistent)

### Persona-UnabhÃ¤ngigkeit
```python
# Jede Persona ist eine eigene "Person"
Anna.respond(question, previous_responses=[])  # Keine anderen Antworten
Tom.respond(question, previous_responses=[])   # Nur eigener Kontext
Julia.respond(question, previous_responses=[]) # UnabhÃ¤ngige Meinung
```

## ğŸ› ï¸ Anpassung

### Neue Personas hinzufÃ¼gen
```python
def create_neue_persona():
    return PersonaAgent(
        name="Max",
        age=25,
        characteristics="technikaffin, innovativ",
        background="Software-Entwickler...",
        detailed_personality="Du liebst neue Technologien..."
    )
```

### AI-Modell wechseln
In `.env` Ã¤ndern:
```
DEFAULT_MODEL=mistralai/mistral-small-24b-instruct-2501:free
```

## ğŸ” Fehlerbehebung

- **API-SchlÃ¼ssel fehlt**: `.env` Datei prÃ¼fen
- **AbhÃ¤ngigkeiten fehlen**: `pip install -r requirements.txt`
- **Python fehlt**: Python 3.8+ von https://python.org installieren
- **Windows PowerShell**: Verwenden Sie `.\run.bat` statt `run.bat`
- **Command Prompt empfohlen**: Ã–ffnen Sie `cmd` statt PowerShell fÃ¼r beste KompatibilitÃ¤t
- **Test**: `python agents.py`

## ğŸ“š Tech Stack & Rationale

### Core Technologies
- **ğŸ Python 3.8+** - Robust, weitverbreitet, groÃŸe AI-Community
- **ğŸ”— LangChain** - De-facto Standard fÃ¼r AI-Anwendungen, vereinfacht Prompt-Management
- **ğŸŒ OpenRouter** - KostengÃ¼nstigster Zugang zu hochwertigen AI-Modellen
- **ğŸ¤– Mistral AI** - Beste kostenlose Option: mehrsprachig, konsistent, schnell

### Warum diese Kombination?
- **Kosten**: VÃ¶llig kostenfrei durch OpenRouter + Mistral
- **QualitÃ¤t**: Professionelle Ergebnisse ohne Kompromisse
- **Entwicklung**: Schnelle Iteration durch LangChain-Abstraktion
- **Skalierung**: Einfacher Wechsel zu anderen Modellen bei Bedarf

**Gesamtkosten: 0â‚¬** ğŸ’° (Ideal fÃ¼r Experimente und kleine Projekte)

---

**MIT License** | **Viel SpaÃŸ beim Experimentieren! ğŸš€**
