# Synthetisches Interview System ğŸ¤

Automatisierte synthetische Interviews mit AI-Personas fÃ¼r Lifestyle-Marken-Forschung mit LangChain und OpenRouter.

**ğŸ“¦ Repository:** [github.com/thetabish/ai-personas](https://github.com/thetabish/ai-personas)

## Vor dem Start: API-SchlÃ¼ssel besorgen

**5-Sekunden Setup:**
1. Gehen Sie zu: https://openrouter.ai/mistralai/mistral-small-24b-instruct-2501:free/api
2. Erstellen Sie einen kostenlosen Account
3. Kopieren Sie Ihren API-SchlÃ¼ssel (beginnt mit `sk-or-v1-...`)
4. **SchlÃ¼ssel wird automatisch abgefragt!** â¬‡ï¸

## ğŸš€ Schnell-Start (5 Minuten)

### Linux/macOS:
```bash
# SSH (empfohlen)
git clone git@github.com:thetabish/ai-personas.git
# oder HTTPS
git clone https://github.com/thetabish/ai-personas.git

cd ai-personas
chmod +x run.sh && ./run.sh
# Script fragt automatisch nach API-SchlÃ¼ssel falls keiner vorhanden
```

### Windows:
```cmd
REM Command Prompt (cmd) - Empfohlen
git clone https://github.com/thetabish/ai-personas.git
cd ai-personas
run.bat
```

```powershell
# PowerShell - Alternative
git clone https://github.com/thetabish/ai-personas.git
cd ai-personas
.\run.bat
# oder: cmd /c run.bat
```

> **Was machen die Scripts?** `run.sh` und `run.bat` sind vollautomatische Setup-Scripts, die:
> - Python-Installation prÃ¼fen
> - Virtuelle Umgebung erstellen  
> - Alle AbhÃ¤ngigkeiten installieren
> - API-SchlÃ¼ssel interaktiv abfragen (falls fehlend)
> - Sofort eine Demo mit 3 AI-Personas starten

**Das war's!** Die Scripts richten automatisch alles ein:
âœ… Python prÃ¼fen âœ… AbhÃ¤ngigkeiten installieren âœ… **API interaktiv eingeben** âœ… Demo starten

**ğŸ’¡ Windows-Tipp:** Bei PowerShell verwenden Sie `.\run.bat` - Command Prompt (cmd) ist empfohlen!

**Demo-Ergebnis:** 3 AI-Personas (Anna, Tom, Julia) beantworten Lifestyle-Fragen
- Ausgabe: `results.json` (Daten) und `results.md` (Bericht)

## âœ¨ Features

- ğŸ¤– **3 einzigartige AI-Personas** (Anna, Tom, Julia)
- ğŸ¯ **Flexibler Interview-Modus** (alle Personas oder einzeln)
- ğŸ”— **LangChain + OpenRouter** (kostenlos)
- ğŸ“ **JSON-Fragensystem** (einfach anpassbar)
- ğŸ’» **CLI & Python API** (Kommandozeile + programmierbar)
- ğŸ“Š **JSON/Markdown Ausgabe** (strukturierte Daten + Berichte)
- ğŸ§  **UnabhÃ¤ngige Persona-GedÃ¤chtnisse** (konsistente Antworten)
- âš¡ **Kostenfrei** (Mistral AI Ã¼ber OpenRouter)

## ğŸ”§ Manuelle Installation

**Voraussetzungen:** Python 3.8+

```bash
# 1. Repository klonen
git clone git@github.com:thetabish/ai-personas.git
# oder: git clone https://github.com/thetabish/ai-personas.git
cd ai-personas

# 2. AbhÃ¤ngigkeiten installieren
pip install -r requirements.txt

# 3. API-SchlÃ¼ssel einrichten
cp .env.example .env
# Bearbeiten Sie .env und fÃ¼gen Sie Ihren OpenRouter API-SchlÃ¼ssel ein:
# OPENROUTER_API_KEY=sk-or-v1-ihr_schluessel_hier
# SchlÃ¼ssel erhalten: https://openrouter.ai/mistralai/mistral-small-24b-instruct-2501:free/api

# 4. Demo starten
python interview.py --questions questions.json
```

## ğŸ’» Verwendung

### CLI (Kommandozeile)
```bash
# Basis-Interview (alle Personas, Markdown-Ausgabe)
python interview.py --questions questions.json

# JSON-Format gewÃ¼nscht
python interview.py --questions questions.json --format json

# Eigene Ausgabedatei  
python interview.py --questions questions.json --output meine_befragung
```

### Programmable API (Python Import)

**Flexibler `run_interview()` - zwei Modi:**

#### 1. Alle Personas (Standard)
```python
from interview import run_interview

# Alle 3 Personas antworten (Anna, Tom, Julia)
results = run_interview("questions.json")

# Mit Format-Optionen
results = run_interview("questions.json", format="json")
results = run_interview("questions.json", output_file="my_study")
```

#### 2. Einzelne Persona
```python
# Nur Anna antwortet
results = run_interview("anna", "questions.json")

# Nur Tom antwortet
results = run_interview("tom", "questions.json") 

# Nur Julia antwortet
results = run_interview("julia", "questions.json")

# Mit Format-Optionen
results = run_interview("anna", "questions.json", format="json")
```

**VerfÃ¼gbare Agenten abrufen:**
```python
from interview import get_available_agents
agents = get_available_agents()  # ['anna', 'tom', 'julia']
```

### Eigene Fragen erstellen
```json
{
  "questions": [
    "Ihre erste Frage hier",
    "Ihre zweite Frage hier"
  ]
}
```

## ğŸ—ï¸ Technische Architektur & Entscheidungen

### Warum Mistral AI?
- **Kostenlos**: Mistral Small Ã¼ber OpenRouter ist vÃ¶llig kostenlos
- **QualitÃ¤t**: Hochwertiges mehrsprachiges Modell (DE/EN)
- **Performance**: Schnelle Antwortzeiten fÃ¼r Interviews
- **Konsistenz**: Stabile Persona-Charakteristiken

### Warum OpenRouter?
- **Kostenkontrolle**: Kostenlose Modelle ohne versteckte GebÃ¼hren
- **Einfachheit**: Ein API-SchlÃ¼ssel fÃ¼r viele AI-Modelle
- **ZuverlÃ¤ssigkeit**: Professioneller API-Gateway mit hoher VerfÃ¼gbarkeit
- **FlexibilitÃ¤t**: Einfacher Modellwechsel ohne Code-Ã„nderungen

### LangChain Integration
```python
# Vereinfachter Workflow:
PersonaAgent â†’ LangChain â†’ OpenRouter â†’ Mistral AI â†’ Antwort
```

**Warum LangChain?**
- **Abstraktion**: Einheitliche Schnittstelle fÃ¼r verschiedene AI-Modelle
- **Kontext-Management**: Automatische Verwaltung von GesprÃ¤chsverlÃ¤ufen
- **Prompt-Engineering**: Strukturierte Prompts fÃ¼r konsistente Ergebnisse
- **Zukunftssicherheit**: Einfacher Wechsel zwischen AI-Anbietern

### Programm-Flow
1. **Setup**: API-Validierung â†’ Persona-Erstellung (LangChain)
2. **Interview**: Jede Persona antwortet unabhÃ¤ngig (eigener Kontext)
3. **Speicherung**: Strukturierte JSON/Markdown-Ausgabe
4. **GedÃ¤chtnis**: Personas erinnern sich an eigene Antworten (konsistent)

### Persona-UnabhÃ¤ngigkeit
```python
# Jede Persona ist eine eigene "Person"
Anna.respond(question, previous_responses=[])  # Keine anderen Antworten
Tom.respond(question, previous_responses=[])   # Nur eigener Kontext
Julia.respond(question, previous_responses=[]) # UnabhÃ¤ngige Meinung
```

## ğŸ› ï¸ Anpassung

### Neue Personas hinzufÃ¼gen
```python
def create_neue_persona():
    return PersonaAgent(
        name="Max",
        age=25,
        characteristics="technikaffin, innovativ",
        background="Software-Entwickler...",
        detailed_personality="Du liebst neue Technologien..."
    )
```

### AI-Modell wechseln
In `.env` Ã¤ndern:
```
DEFAULT_MODEL=mistralai/mistral-small-24b-instruct-2501:free
```

## ğŸ” Fehlerbehebung

- **API-SchlÃ¼ssel fehlt**: `.env` Datei prÃ¼fen
- **AbhÃ¤ngigkeiten fehlen**: `pip install -r requirements.txt`
- **Python fehlt**: Python 3.8+ von https://python.org installieren
- **Windows PowerShell**: Verwenden Sie `.\run.bat` statt `run.bat`
- **Command Prompt empfohlen**: Ã–ffnen Sie `cmd` statt PowerShell fÃ¼r beste KompatibilitÃ¤t
- **Test**: `python agents.py`

## ğŸ“š Tech Stack & Rationale

### Core Technologies
- **ğŸ Python 3.8+** - Robust, weitverbreitet, groÃŸe AI-Community
- **ğŸ”— LangChain** - De-facto Standard fÃ¼r AI-Anwendungen, vereinfacht Prompt-Management
- **ğŸŒ OpenRouter** - KostengÃ¼nstigster Zugang zu hochwertigen AI-Modellen
- **ğŸ¤– Mistral AI** - Beste kostenlose Option: mehrsprachig, konsistent, schnell

### Warum diese Kombination?
- **Kosten**: VÃ¶llig kostenfrei durch OpenRouter + Mistral
- **QualitÃ¤t**: Professionelle Ergebnisse ohne Kompromisse
- **Entwicklung**: Schnelle Iteration durch LangChain-Abstraktion
- **Skalierung**: Einfacher Wechsel zu anderen Modellen bei Bedarf

**Gesamtkosten: 0â‚¬** ğŸ’° (Ideal fÃ¼r Experimente und kleine Projekte)

---

**MIT License** | **Viel SpaÃŸ beim Experimentieren! ğŸš€**
